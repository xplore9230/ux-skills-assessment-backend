#!/usr/bin/env python3
"""
Import Knowledge Bank Resources into Vector Store
==================================================

This script imports resources from the exported knowledge bank JSON file
into the vector database, checking for duplicates by URL.

Usage:
    python import_knowledge_bank.py [--dry-run] [--limit N] [--json-file PATH]
"""

import sys
import os
import json
import argparse
from typing import List, Dict, Any
from urllib.parse import urlparse

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

from knowledge_base import UXResource, ContentChunker
from vector_store import get_vector_store


def level_to_difficulty(level: str) -> str:
    """
    Map knowledge bank level to difficulty.
    """
    mapping = {
        'explorer': 'beginner',
        'practitioner': 'intermediate',
        'emerging-senior': 'intermediate',
        'strategic-lead': 'advanced'
    }
    return mapping.get(level, 'beginner')


def extract_domain(url: str) -> str:
    """Extract domain name from URL."""
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.replace('www.', '')
        return domain
    except:
        return ""


def estimate_read_time_from_duration(duration: str) -> int:
    """Convert duration string to minutes."""
    if not duration:
        return 5  # Default
    
    import re
    # Extract numbers
    numbers = re.findall(r'\d+', duration)
    if numbers:
        num = int(numbers[0])
        if 'min' in duration.lower():
            return num
        elif 'hour' in duration.lower() or 'hr' in duration.lower():
            return num * 60
    return 5  # Default


def knowledge_bank_to_ux_resource(kb_resource: Dict[str, Any]) -> UXResource:
    """
    Convert knowledge bank resource to UXResource.
    """
    url = kb_resource['url']
    resource_id = UXResource.generate_id(url)
    
    # Map resource type
    kb_type = kb_resource.get('type', 'article')
    resource_type_map = {
        'article': 'article',
        'video': 'video',
        'podcast': 'podcast'
    }
    resource_type = resource_type_map.get(kb_type, 'article')
    
    # Use summary as content (knowledge bank doesn't have full content)
    # For imported resources, we'll use the summary as the main content
    content = kb_resource.get('summary', kb_resource.get('title', ''))
    
    # Create UXResource
    return UXResource(
        id=resource_id,
        title=kb_resource['title'],
        url=url,
        content=content,  # Using summary as content
        summary=kb_resource.get('summary', ''),
        category=kb_resource['category'],
        resource_type=resource_type,
        difficulty=level_to_difficulty(kb_resource['level']),
        tags=kb_resource.get('tags', []),
        author=kb_resource.get('author', ''),
        source=extract_domain(url) or kb_resource.get('source', ''),
        publish_date='',
        estimated_read_time=estimate_read_time_from_duration(kb_resource.get('duration', ''))
    )


def get_existing_urls(vs) -> set:
    """Get all existing URLs from vector store."""
    try:
        all_data = vs.collection.get()
        existing_urls = set()
        
        for metadata in all_data.get('metadatas', []):
            url = metadata.get('url')
            if url:
                existing_urls.add(url)
        
        return existing_urls
    except Exception as e:
        print(f"  ‚ö† Error getting existing URLs: {e}")
        return set()


def main():
    parser = argparse.ArgumentParser(
        description="Import knowledge bank resources into vector store",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Preview changes (dry run)
  python import_knowledge_bank.py --dry-run
  
  # Import all resources
  python import_knowledge_bank.py
  
  # Test with first 10 resources
  python import_knowledge_bank.py --limit 10
  
  # Use custom JSON file
  python import_knowledge_bank.py --json-file custom_export.json
        """
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Preview changes without applying them'
    )
    
    parser.add_argument(
        '--limit',
        type=int,
        help='Limit number of resources to process (for testing)'
    )
    
    parser.add_argument(
        '--json-file',
        type=str,
        default='server_py/knowledge_bank_export.json',
        help='Path to knowledge bank JSON export file'
    )
    
    args = parser.parse_args()
    
    print("\n" + "="*70)
    print("  IMPORT KNOWLEDGE BANK INTO VECTOR STORE")
    print("="*70 + "\n")
    
    if args.dry_run:
        print("üîç DRY RUN MODE - No changes will be applied\n")
    
    # Load JSON file
    print(f"üìñ Loading knowledge bank from {args.json_file}...")
    if not os.path.exists(args.json_file):
        print(f"‚ùå Error: JSON file not found: {args.json_file}")
        print(f"\nüí° First export the knowledge bank:")
        print(f"   node scripts/export-knowledge-bank.mjs")
        return 1
    
    try:
        with open(args.json_file, 'r', encoding='utf-8') as f:
            kb_resources = json.load(f)
        print(f"   Found {len(kb_resources)} resources in knowledge bank")
    except Exception as e:
        print(f"‚ùå Error loading JSON file: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    if args.limit:
        kb_resources = kb_resources[:args.limit]
        print(f"   Limited to first {args.limit} resources\n")
    
    # Get vector store
    print("üîç Checking existing resources in vector store...")
    vs = get_vector_store()
    existing_urls = get_existing_urls(vs)
    print(f"   Found {len(existing_urls)} existing resources\n")
    
    # Convert and check for duplicates
    print("üîÑ Converting and checking for duplicates...\n")
    
    chunker = ContentChunker(chunk_size=500, overlap=50, min_chunk_size=100)
    ux_resources = []
    duplicates = []
    new_resources = []
    errors = []
    
    for kb_res in kb_resources:
        try:
            ux_res = knowledge_bank_to_ux_resource(kb_res)
            ux_resources.append(ux_res)
            
            if ux_res.url in existing_urls:
                duplicates.append({
                    'title': ux_res.title,
                    'url': ux_res.url,
                    'category': ux_res.category
                })
            else:
                new_resources.append(ux_res)
        except Exception as e:
            errors.append({
                'resource': kb_res.get('title', 'unknown'),
                'error': str(e)
            })
            print(f"  ‚ö† Error converting resource {kb_res.get('title', 'unknown')[:50]}...: {e}")
    
    # Report duplicates
    if duplicates:
        print(f"\n‚ö† Found {len(duplicates)} duplicates (will be skipped):\n")
        for dup in duplicates[:10]:  # Show first 10
            print(f"   - {dup['title'][:60]}...")
            print(f"     URL: {dup['url']}")
        if len(duplicates) > 10:
            print(f"   ... and {len(duplicates) - 10} more\n")
        else:
            print()
    
    # Report errors
    if errors:
        print(f"\n‚ö† Found {len(errors)} conversion errors:\n")
        for err in errors[:5]:
            print(f"   - {err['resource']}: {err['error']}")
        if len(errors) > 5:
            print(f"   ... and {len(errors) - 5} more\n")
    
    # Check for resources that need difficulty updates
    print(f"üîÑ Checking for resources that need difficulty updates...\n")
    needs_update = []
    
    for ux_res in ux_resources:
        if ux_res.url in existing_urls:
            # Check if difficulty needs updating
            try:
                # Get existing resource metadata
                existing_results = vs.collection.get(
                    where={"url": ux_res.url},
                    limit=1
                )
                if existing_results['metadatas']:
                    existing_difficulty = existing_results['metadatas'][0].get('difficulty', 'beginner')
                    new_difficulty = ux_res.difficulty
                    if existing_difficulty != new_difficulty:
                        needs_update.append({
                            'resource': ux_res,
                            'old_difficulty': existing_difficulty,
                            'new_difficulty': new_difficulty
                        })
            except Exception as e:
                print(f"  ‚ö† Error checking {ux_res.title[:50]}...: {e}")
    
    if needs_update:
        print(f"üìù Found {len(needs_update)} resources that need difficulty updates:\n")
        for item in needs_update[:10]:
            print(f"   - {item['resource'].title[:60]}...")
            print(f"     {item['old_difficulty']} ‚Üí {item['new_difficulty']}")
        if len(needs_update) > 10:
            print(f"   ... and {len(needs_update) - 10} more\n")
        else:
            print()
    else:
        print(f"   ‚úì All {len(ux_resources)} resources have correct difficulty levels\n")
    
    # Import new resources
    print(f"üì• Ready to import {len(new_resources)} new resources\n")
    
    updated = 0
    failed_updates = 0
    
    if not args.dry_run:
        # Update existing resources' difficulty
        if needs_update:
            print("üîÑ Updating difficulty levels for existing resources...\n")
            updated = 0
            failed_updates = 0
            
            for item in needs_update:
                try:
                    resource = item['resource']
                    # Get all chunks for this resource
                    results = vs.collection.get(
                        where={"url": resource.url}
                    )
                    
                    if results['ids']:
                        # Update metadata for each chunk
                        updated_metadatas = []
                        for metadata in results['metadatas']:
                            metadata['difficulty'] = resource.difficulty
                            updated_metadatas.append(metadata)
                        
                        # Update in ChromaDB
                        vs.collection.update(
                            ids=results['ids'],
                            metadatas=updated_metadatas
                        )
                        updated += 1
                        if updated % 10 == 0:
                            print(f"  ‚úì Updated {updated}/{len(needs_update)} resources...")
                except Exception as e:
                    failed_updates += 1
                    print(f"  ‚úó Error updating {item['resource'].title[:50]}...: {e}")
            
            print(f"\n  ‚úì Updated {updated} resources")
            if failed_updates > 0:
                print(f"  ‚úó Failed to update {failed_updates} resources\n")
        
        if new_resources:
            print("üíæ Importing resources...\n")
            added = 0
            failed = 0
            
            for i, res in enumerate(new_resources, 1):
                try:
                    if vs.resource_exists(res.id):
                        continue
                    
                    chunks = chunker.create_chunks(res)
                    if not chunks:
                        print(f"  ‚ö† [{i}/{len(new_resources)}] No chunks created for: {res.title[:50]}...")
                        continue
                    
                    if vs.add_resource(res, chunks):
                        added += 1
                        if added % 10 == 0:
                            print(f"  ‚úì Imported {added}/{len(new_resources)} resources...")
                except Exception as e:
                    failed += 1
                    print(f"  ‚úó [{i}/{len(new_resources)}] Error importing {res.title[:50]}...: {e}")
            
            print()
            print("="*70)
            print("  SUMMARY")
            print("="*70)
            print(f"  Total knowledge bank resources: {len(kb_resources)}")
            print(f"  Duplicates found (skipped):      {len(duplicates)}")
            print(f"  Resources updated (difficulty):  {updated if needs_update else 0}")
            print(f"  Conversion errors:               {len(errors)}")
            print(f"  New resources imported:          {added}")
            print(f"  Failed imports:                  {failed}")
            if needs_update and failed_updates > 0:
                print(f"  Failed updates:                  {failed_updates}")
            print("="*70 + "\n")
            
            # Show new category distribution
            if added > 0:
                print("üìä New Category Distribution:")
                categories = {}
                for res in new_resources[:added]:
                    cat = res.category
                    categories[cat] = categories.get(cat, 0) + 1
                
                for cat, count in sorted(categories.items()):
                    print(f"   {cat:30s}: {count:3d} resources")
                print()
        
    elif args.dry_run:
        print("="*70)
        print("  PREVIEW SUMMARY")
        print("="*70)
        print(f"  Total knowledge bank resources: {len(kb_resources)}")
        print(f"  Duplicates found (would skip):  {len(duplicates)}")
        print(f"  Resources needing update:        {len(needs_update)}")
        print(f"  Conversion errors:              {len(errors)}")
        print(f"  New resources (would import):   {len(new_resources)}")
        print()
        print("  ‚ÑπÔ∏è  Run without --dry-run to import and update")
        print("="*70 + "\n")
    
    return 0


if __name__ == '__main__':
    sys.exit(main())

